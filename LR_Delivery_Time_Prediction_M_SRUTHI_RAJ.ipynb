{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c30991a",
   "metadata": {},
   "source": [
    "# LR Delivery Time Prediction — Final Submission\n",
    "\n",
    "**Name:** M SRUTHI RAJ\n",
    "\n",
    "**Assignment:** Linear Regression — Parcel Delivery Time Estimation\n",
    "\n",
    "**Files included:** Notebook, PDF report, outputs (plots & artifacts), dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and display settings\n",
    "import pandas as pd, numpy as np, os\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib, statsmodels.api as sm\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a420d349",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Dataset `porter_data_1.csv` is included in the ZIP. The notebook recreates the preprocessing and modeling steps used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'porter_data_1.csv'\n",
    "assert os.path.exists(DATA_PATH), \"Dataset file porter_data_1.csv must be in the same folder as the notebook.\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Loaded shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delivery_minutes target if required\n",
    "if 'delivery_minutes' not in df.columns and {'created_at','actual_delivery_time'}.issubset(df.columns):\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "    df['actual_delivery_time'] = pd.to_datetime(df['actual_delivery_time'], errors='coerce')\n",
    "    df['delivery_minutes'] = (df['actual_delivery_time'] - df['created_at']).dt.total_seconds() / 60.0\n",
    "target = 'delivery_minutes'\n",
    "print('Target stats:'); display(df[target].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e58fe12",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Feature Engineering\n",
    "- Fill missing values\n",
    "- Create time features if timestamps exist\n",
    "- Encode categorical variables (label-encode market_id; one-hot small categorical cols)\n",
    "- Scale numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing and feature creation\n",
    "df = df.dropna(subset=[target]).copy()\n",
    "if 'created_at' in df.columns:\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "    df['order_hour'] = df['created_at'].dt.hour\n",
    "    df['order_weekday'] = df['created_at'].dt.weekday\n",
    "\n",
    "for c in ['market_id','store_primary_category','order_protocol']:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype('category')\n",
    "\n",
    "# Train-test split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print('Train, Val shapes:', train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select core numeric features present in dataset\n",
    "numeric_candidates = ['total_items','subtotal','num_distinct_items','min_item_price','max_item_price','total_onshift_dashers','total_busy_dashers','total_outstanding_orders','distance']\n",
    "core_numeric = [c for c in numeric_candidates if c in train_df.columns]\n",
    "\n",
    "# Fill numeric missing values with median\n",
    "for c in core_numeric:\n",
    "    med = train_df[c].median()\n",
    "    train_df[c] = train_df[c].fillna(med)\n",
    "    val_df[c] = val_df[c].fillna(med)\n",
    "\n",
    "# Label-encode market_id to avoid many dummies\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_feats = []\n",
    "if 'market_id' in train_df.columns:\n",
    "    le = LabelEncoder()\n",
    "    train_df['market_id_le'] = le.fit_transform(train_df['market_id'].astype(str))\n",
    "    val_df['market_id_le'] = le.transform(val_df['market_id'].astype(str))\n",
    "    categorical_feats.append('market_id_le')\n",
    "\n",
    "# One-hot small categorical columns\n",
    "ohe_cols = [c for c in ['store_primary_category','order_protocol'] if c in train_df.columns]\n",
    "X_train = train_df[core_numeric + categorical_feats + ohe_cols].copy()\n",
    "X_val = val_df[core_numeric + categorical_feats + ohe_cols].copy()\n",
    "X_train = pd.get_dummies(X_train, columns=ohe_cols, drop_first=True)\n",
    "X_val = pd.get_dummies(X_val, columns=ohe_cols, drop_first=True)\n",
    "X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "y_train = train_df[target].values\n",
    "y_val = val_df[target].values\n",
    "\n",
    "print('Feature matrix shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a904365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap numeric outliers at 1st and 99th percentiles and scale numeric features\n",
    "for c in core_numeric:\n",
    "    lower = train_df[c].quantile(0.01); upper = train_df[c].quantile(0.99)\n",
    "    X_train[c] = X_train[c].clip(lower,upper)\n",
    "    X_val[c] = X_val[c].clip(lower,upper)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if core_numeric:\n",
    "    X_train[core_numeric] = scaler.fit_transform(X_train[core_numeric])\n",
    "    X_val[core_numeric] = scaler.transform(X_val[core_numeric])\n",
    "\n",
    "# Save scaler for reproducibility\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61225c1d",
   "metadata": {},
   "source": [
    "## 3. Baseline Linear Regression\n",
    "Train a baseline OLS and evaluate on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train); y_pred_val = lr.predict(X_val)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    return {'rmse': mean_squared_error(y_true,y_pred,squared=False),\n",
    "            'mae': mean_absolute_error(y_true,y_pred),\n",
    "            'r2': r2_score(y_true,y_pred)}\n",
    "\n",
    "print('Train metrics:', metrics(y_train, y_pred_train))\n",
    "print('Val metrics  :', metrics(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ba8c9",
   "metadata": {},
   "source": [
    "## 4. Select top features by coefficient magnitude and retrain\n",
    "(Practical, fast alternative to RFE for large datasets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 12 features by absolute coefficient from baseline model\n",
    "coef_series = pd.Series(lr.coef_, index=X_train.columns).abs().sort_values(ascending=False)\n",
    "topN = min(12, len(coef_series))\n",
    "top_features = coef_series.head(topN).index.tolist()\n",
    "print('Top features:', top_features)\n",
    "\n",
    "# Retrain on top features\n",
    "X_train_top = X_train[top_features].copy()\n",
    "X_val_top = X_val[top_features].copy()\n",
    "lr_top = LinearRegression().fit(X_train_top, y_train)\n",
    "y_pred_val_top = lr_top.predict(X_val_top)\n",
    "print('Top-features val metrics:', metrics(y_val, y_pred_val_top))\n",
    "\n",
    "# Save final model\n",
    "joblib.dump(lr_top, 'final_lr_model_top.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8232de",
   "metadata": {},
   "source": [
    "## 5. Interpretability & Diagnostics\n",
    "- Statsmodels OLS summary for selected features\n",
    "- Residual plots and QQ-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels OLS\n",
    "X_sm = sm.add_constant(X_train_top)\n",
    "ols = sm.OLS(y_train, X_sm).fit()\n",
    "print(ols.summary())\n",
    "\n",
    "# Residual diagnostics on validation set\n",
    "import matplotlib.pyplot as plt\n",
    "y_val_pred = lr_top.predict(X_val_top)\n",
    "residuals = y_val - y_val_pred\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_val_pred, residuals, alpha=0.2); plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Residuals'); plt.title('Residuals vs Predicted'); plt.show()\n",
    "\n",
    "sm.qqplot(residuals, line='45'); plt.title('QQ-plot of residuals'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a19821c",
   "metadata": {},
   "source": [
    "## 6. Save important plots and artifacts\n",
    "(Plots saved to `outputs/` for inclusion in the PDF/report.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad96514",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs', exist_ok=True)\n",
    "# Target distribution\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(train_df[target], bins=60, kde=True)\n",
    "plt.title('Target distribution (train)'); plt.savefig('outputs/target_distribution.png', dpi=150); plt.close()\n",
    "# Correlation heatmap for numeric features\n",
    "num_for_corr = core_numeric.copy()\n",
    "if core_numeric:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    corr = train_df[num_for_corr + [target]].corr()\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.title('Correlation heatmap (train)'); plt.savefig('outputs/correlation_heatmap.png', dpi=150); plt.close()\n",
    "\n",
    "# Actual vs predicted (Val)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_val, y_pred_val_top, alpha=0.2)\n",
    "plt.plot([y_val.min(), y_val.max()],[y_val.min(), y_val.max()],'r--')\n",
    "plt.xlabel('Actual'); plt.ylabel('Predicted'); plt.title('Actual vs Predicted (Val)'); plt.savefig('outputs/actual_vs_predicted_val.png', dpi=150); plt.close()\n",
    "\n",
    "# Residuals and QQ already plotted above; save residuals plot and qq as files\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred_val_top, residuals, alpha=0.2); plt.axhline(0,color='r',linestyle='--')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Residuals'); plt.title('Residuals vs Predicted'); plt.savefig('outputs/residuals_vs_predicted.png', dpi=150); plt.close()\n",
    "\n",
    "import statsmodels.api as smm\n",
    "fig = smm.qqplot(residuals, line='45', fit=True); fig.savefig('outputs/qqplot_residuals.png', dpi=150); plt.close(fig)\n",
    "\n",
    "# Save feature importance table\n",
    "pd.DataFrame({'feature': top_features}).to_csv('outputs/selected_features.csv', index=False)\n",
    "\n",
    "# Save models in outputs/artifacts\n",
    "os.makedirs('outputs/artifacts', exist_ok=True)\n",
    "shutil.copy('final_lr_model_top.joblib', 'outputs/artifacts/final_lr_model_top.joblib')\n",
    "shutil.copy('scaler.joblib', 'outputs/artifacts/scaler.joblib')\n",
    "\n",
    "print('Saved outputs in outputs/ directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19897c77",
   "metadata": {},
   "source": [
    "## 7. Conclusions & Recommendations\n",
    "\n",
    "- Summarize model performance (RMSE/MAE/R²) and interpret top features.\n",
    "- Provide operational recommendations (staffing, routing, micro-hubs) and limitations.\n",
    "\n",
    "---\n",
    "\n",
    "**End of notebook**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
